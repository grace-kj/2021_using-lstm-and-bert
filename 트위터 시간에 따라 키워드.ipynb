{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c049c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import time\n",
    "import GetOldTweets3 as got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee48bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"l5QjEyheo2lkqWmt6SCAwdrll\"\n",
    "consumer_secret = \"SI0ceaSqKi4KJurVjLIExWMEXHEU2TiGzzKEhXBuo6LIwWaFEP\"\n",
    "access_token = \"1312660164135194625-BhA3rY2jyPH6Hb2IXBWkQQiuvyc5nz\"\n",
    "access_token_secret = \"0pYb0UVtMg5ukg8VQxO0RE6DqnwcDTvnVGZTqiv0pVn1E\"\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "024c5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "c = twint.Config() # twint config 선언\n",
    "\n",
    "# Parameter setting\n",
    "c.Limit = 100\n",
    "c.Search = '집값'\n",
    "c.Since = '2019-01-01'\n",
    "c.Until = '2019-01-10'\n",
    "c.Output = 'price_sample_tweet2019.json'\n",
    "c.Popular_tweets = True\n",
    "c.Store_json = True\n",
    "c.Hide_output = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e44b9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "10379ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('price_sample_tweet2019.json', lines=True)\n",
    "dataset=df[[\"id\", \"tweet\", \"retweets_count\"]]\n",
    "dataset=dataset[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8df40322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8e5bbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns=['id','document','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "73edcd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test= dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1532c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import gluonnlp as nlp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import urllib.request\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141e7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "n_devices = torch.cuda.device_count()\n",
    "print(n_devices)\n",
    "\n",
    "for i in range(n_devices):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "053f1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배치 및 데이터로더 설정\n",
    "\n",
    "BATCH_SIZE = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "57f1f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 셋에도 똑같이 적용\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "MAX_LEN = 128\n",
    "\n",
    "sentences = dataset_test['document']\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "labels = dataset_test['label'].values\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "attention_masks = []\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f5cd18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "#모델 학습\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae240c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('C:\\\\Users\\\\AAA\\\\Desktop\\\\dev\\\\트위터 api\\\\modeltrained.pt')\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4615f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy와 시간함수\n",
    "\n",
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "875f0355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.33\n",
      "Test took: 0:00:02\n",
      "[0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "lab=[]\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    out= logits.flatten().tolist()\n",
    "    lab.append(out.index(max(out)))\n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "195b6631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1083142372655955969</td>\n",
       "      <td>앑) 그때 집값이 많이 올랐지...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1083139609477804032</td>\n",
       "      <td>코딱지만한 돈으로 쉽게 구해지겠어요? 반지하에서 계단 몇 개 올라가는데 집값은 초고...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1083138836585078784</td>\n",
       "      <td>file:///C:/Users/jmkim/Documents/블로그한글%20조인스/0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1083124871607967744</td>\n",
       "      <td>집도 구해야 하는데 일도 해야하고 우주도...공부도 등록금도 집값도 여행도 다 자신...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1083081741621911553</td>\n",
       "      <td>야, 이거 그래도 히스토릭 서비스 반장까지 했는데 집이 뭐 이 모양이냐. 이 동네 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1083072760975450113</td>\n",
       "      <td>@alldrinaforth 감사합니다. 다행이 저희 동네는 집은 많아서 좋습니다. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1083053813836132352</td>\n",
       "      <td>볼려고 찍어놨던 집들이 하나 둘 집값을 내린다. 크게는 거의 10%까지. 더 기달려...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1083036962557091840</td>\n",
       "      <td>D - 40 드디어 40일 남았어여요 하루하루가 고비지만 나름 잘 참고있어요 40일...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1083029805098926081</td>\n",
       "      <td>ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ집단살해 사건 있던 건물로 이사 왔냐...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1083026995640819712</td>\n",
       "      <td>@etwewzz @etwewzz 그 드라마가 그래서 부모들 사회경제적 계층이 애매하...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1083006859798147073</td>\n",
       "      <td>영혼을 빼앗기면 괴물이 된다. 어느 순간 우린,  파업한 사람을 개 패듯 끌고 나와...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1083000398405787648</td>\n",
       "      <td>@ppptec 수도이전 토지공개념으로 집값을 절반으로 떨어뜨려야 합니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1082998166494965760</td>\n",
       "      <td>@hecate_mm @the_KIMLEO @mrng_aa 다들 그렇게 사더라구요.....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1082989307676155904</td>\n",
       "      <td>서울이라는 도시의 다양한 모습을 보호하고 보전해서 '상생'했으면 하는 마음이 크다....</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1082984738606899201</td>\n",
       "      <td>@L_Phase 서울 근처로 가고싶은데 집값이..</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1082973348160692225</td>\n",
       "      <td>와 저기에 보험이랑 통신비 집값하면 기냥 저금할 돈도 없이 한달 벌고 한달 살고</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1082962380504453120</td>\n",
       "      <td>@crema_k 집값 너무 비싸요ㅜ 동생도 엄마랑 싸워서 집 나가려고 했다가 집값때...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1082961778919727104</td>\n",
       "      <td>을지로에 주상복합은 도시재생보단 재개발 같은데요 박원순 시장님. 문재인 대통령이 열...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1082947080367165440</td>\n",
       "      <td>아니, 저거 초등학교 실과나 중고등학교 가정때도 나오는거 아닌가? 노후 자금이 부족...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1082946683510480897</td>\n",
       "      <td>@TheMinjoo_Kr  거대한 여론 분열 세력에 덫이 잡힌 느낌입니다. (집값을...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1082943038723317760</td>\n",
       "      <td>주안 10구역 관리처분총회 완료했는데 집값이 피가 7천5백 이네요 연락주삼</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1082940339084713984</td>\n",
       "      <td>아무튼 이 원곡이라는 지역 하나 때문에 안산시가 타 지역조차 못사는 동네로 인식되고...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1082936079404085253</td>\n",
       "      <td>\"서울 용산구 한남동 단독주택(대지면적 331㎡)의 경우 공시가격이 16억3000만...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1082933984579878912</td>\n",
       "      <td>@hankyungmedia 대출 받아 세금 내더라도 집값 크게 올라 재산 늘어나고 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1082921764118843394</td>\n",
       "      <td>집값 하락에 ‘깡통주택’확산…전세금 반환 사고 속출  https://t.co/ZeW...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1082921170884644864</td>\n",
       "      <td>수도권 집값 더 떨어져야 하나? 올 봄 분양시장서 참패</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1082906495816060929</td>\n",
       "      <td>2Q 집값 서울은 부진전세 상승세 지속</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1082902656681619456</td>\n",
       "      <td>게다가 안양이나 금천구 일대로 나가는 버스(5530 500 9, 9-3 1)를 타기...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1082901772702703616</td>\n",
       "      <td>와 진짜 가격말고 공시지가가 29억이면 진짜 땅+집값은...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1082893097472684033</td>\n",
       "      <td>중개사 절반 \"올해 서울 집값 안 올라\" | 조선비즈 AMP  https://t.c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1082892627807092736</td>\n",
       "      <td>서울 집값 안정과 서울 중심지 재개발 반대를 동시에 주장하는 사람 보면 좀 어쩌라고...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1082888645877481472</td>\n",
       "      <td>@wonsoonpark 불찰이 하나둘입니까? 여의도용산개발로 집값 폭등. 서울시공무...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1082888558405246982</td>\n",
       "      <td>서울집값 하락시키는데 문정부가 만든게 이니라 헬리오시티가 끌어내리고 있네 ㅋㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1082886582535745537</td>\n",
       "      <td>@mo9rii 홀,,, 대구 집값 좀 알아보아야 겟네요,, 저 글로 가면 놀아주시는...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1082878462971375616</td>\n",
       "      <td>부동산 경기 살린다고 향후 집값 오른다면 국민에게 집사라고 현혹한 자가 누구인지 밝...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1082876835061362689</td>\n",
       "      <td>세계에서  집값이 가장 비싼 나라 톱 10 !! 한국은 몇 등 정도 일까요?  ht...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1082868242505334784</td>\n",
       "      <td>@_Elcy 난 앞으로 집값 내릴거같은데 부모님은 집을 사야 돈을 번다면서 크흡..</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1082866864160526337</td>\n",
       "      <td>가지가지들 한다..집값 내릴까봐 그러는거면서ㅋㅋ ㅋㅋㅋ 🤢🤮  https://t.c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1082866433644650496</td>\n",
       "      <td>그냐앙. 아아~ 후... 우리동네는 세월이 지나도 이렇게 변하질 않냐? 집값도 안 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1082866300517380097</td>\n",
       "      <td>[트윗만평]집을가진이들은 집값이 내려간다고 울며 어렵다하며, 집을가지지못한이들은 집...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1082864182205140992</td>\n",
       "      <td>을지로밀고 뭐 거기에다가 새공장이나 새공업단지 지어서 원래 일하시던분들 옮기라고 하...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1082862237243498496</td>\n",
       "      <td>박원순 집값 잡기 올인…“공공임대주택 40만호 공급”  https://t.co/GT...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1082860975865266176</td>\n",
       "      <td>#참고 공시가격은 실제 집값이 변동하는 상황을 반영하여 결정된 것으로 지역별로 개별...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1082859754815287296</td>\n",
       "      <td>한국감정원 관계자 \"수도권 주택공급 계획, 9·13 대책 등 정부 규제, 금리 인상...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1082856881738137601</td>\n",
       "      <td>[부동산] 올해 부산 집값 떨어질듯  #부산부동산 #주택 #전월세 #집값하락 #부동...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1082852997221081088</td>\n",
       "      <td>집값, 얼마나 떨어져야 거래절벽 탈출할까?  https://t.co/UixRJtat81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1082844711679778816</td>\n",
       "      <td>사실 부자동네에 예전부터 오래산 노인들 중에 살고 있는 집값은 그동안 올라서 서류상...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1082837130357878785</td>\n",
       "      <td>@webber_27_A @Siegeslauf 집값 떨어집니다 (10년째 똑같은 이야기</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1082830108182884352</td>\n",
       "      <td>@coreazang @kjy24k 집값 올라도 세금이나 기타 유지비가 감당이 되지 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                           document  \\\n",
       "0   1083142372655955969                                앑) 그때 집값이 많이 올랐지...   \n",
       "1   1083139609477804032  코딱지만한 돈으로 쉽게 구해지겠어요? 반지하에서 계단 몇 개 올라가는데 집값은 초고...   \n",
       "2   1083138836585078784  file:///C:/Users/jmkim/Documents/블로그한글%20조인스/0...   \n",
       "3   1083124871607967744  집도 구해야 하는데 일도 해야하고 우주도...공부도 등록금도 집값도 여행도 다 자신...   \n",
       "4   1083081741621911553  야, 이거 그래도 히스토릭 서비스 반장까지 했는데 집이 뭐 이 모양이냐. 이 동네 ...   \n",
       "5   1083072760975450113  @alldrinaforth 감사합니다. 다행이 저희 동네는 집은 많아서 좋습니다. ...   \n",
       "6   1083053813836132352  볼려고 찍어놨던 집들이 하나 둘 집값을 내린다. 크게는 거의 10%까지. 더 기달려...   \n",
       "7   1083036962557091840  D - 40 드디어 40일 남았어여요 하루하루가 고비지만 나름 잘 참고있어요 40일...   \n",
       "8   1083029805098926081  ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ집단살해 사건 있던 건물로 이사 왔냐...   \n",
       "9   1083026995640819712  @etwewzz @etwewzz 그 드라마가 그래서 부모들 사회경제적 계층이 애매하...   \n",
       "10  1083006859798147073  영혼을 빼앗기면 괴물이 된다. 어느 순간 우린,  파업한 사람을 개 패듯 끌고 나와...   \n",
       "11  1083000398405787648           @ppptec 수도이전 토지공개념으로 집값을 절반으로 떨어뜨려야 합니다.   \n",
       "12  1082998166494965760  @hecate_mm @the_KIMLEO @mrng_aa 다들 그렇게 사더라구요.....   \n",
       "13  1082989307676155904  서울이라는 도시의 다양한 모습을 보호하고 보전해서 '상생'했으면 하는 마음이 크다....   \n",
       "14  1082984738606899201                        @L_Phase 서울 근처로 가고싶은데 집값이..   \n",
       "15  1082973348160692225       와 저기에 보험이랑 통신비 집값하면 기냥 저금할 돈도 없이 한달 벌고 한달 살고   \n",
       "16  1082962380504453120  @crema_k 집값 너무 비싸요ㅜ 동생도 엄마랑 싸워서 집 나가려고 했다가 집값때...   \n",
       "17  1082961778919727104  을지로에 주상복합은 도시재생보단 재개발 같은데요 박원순 시장님. 문재인 대통령이 열...   \n",
       "18  1082947080367165440  아니, 저거 초등학교 실과나 중고등학교 가정때도 나오는거 아닌가? 노후 자금이 부족...   \n",
       "19  1082946683510480897  @TheMinjoo_Kr  거대한 여론 분열 세력에 덫이 잡힌 느낌입니다. (집값을...   \n",
       "20  1082943038723317760          주안 10구역 관리처분총회 완료했는데 집값이 피가 7천5백 이네요 연락주삼   \n",
       "21  1082940339084713984  아무튼 이 원곡이라는 지역 하나 때문에 안산시가 타 지역조차 못사는 동네로 인식되고...   \n",
       "22  1082936079404085253  \"서울 용산구 한남동 단독주택(대지면적 331㎡)의 경우 공시가격이 16억3000만...   \n",
       "23  1082933984579878912  @hankyungmedia 대출 받아 세금 내더라도 집값 크게 올라 재산 늘어나고 ...   \n",
       "24  1082921764118843394  집값 하락에 ‘깡통주택’확산…전세금 반환 사고 속출  https://t.co/ZeW...   \n",
       "25  1082921170884644864                     수도권 집값 더 떨어져야 하나? 올 봄 분양시장서 참패   \n",
       "26  1082906495816060929                              2Q 집값 서울은 부진전세 상승세 지속   \n",
       "27  1082902656681619456  게다가 안양이나 금천구 일대로 나가는 버스(5530 500 9, 9-3 1)를 타기...   \n",
       "28  1082901772702703616                  와 진짜 가격말고 공시지가가 29억이면 진짜 땅+집값은...   \n",
       "29  1082893097472684033  중개사 절반 \"올해 서울 집값 안 올라\" | 조선비즈 AMP  https://t.c...   \n",
       "30  1082892627807092736  서울 집값 안정과 서울 중심지 재개발 반대를 동시에 주장하는 사람 보면 좀 어쩌라고...   \n",
       "31  1082888645877481472  @wonsoonpark 불찰이 하나둘입니까? 여의도용산개발로 집값 폭등. 서울시공무...   \n",
       "32  1082888558405246982       서울집값 하락시키는데 문정부가 만든게 이니라 헬리오시티가 끌어내리고 있네 ㅋㅋㅋ   \n",
       "33  1082886582535745537  @mo9rii 홀,,, 대구 집값 좀 알아보아야 겟네요,, 저 글로 가면 놀아주시는...   \n",
       "34  1082878462971375616  부동산 경기 살린다고 향후 집값 오른다면 국민에게 집사라고 현혹한 자가 누구인지 밝...   \n",
       "35  1082876835061362689  세계에서  집값이 가장 비싼 나라 톱 10 !! 한국은 몇 등 정도 일까요?  ht...   \n",
       "36  1082868242505334784     @_Elcy 난 앞으로 집값 내릴거같은데 부모님은 집을 사야 돈을 번다면서 크흡..   \n",
       "37  1082866864160526337  가지가지들 한다..집값 내릴까봐 그러는거면서ㅋㅋ ㅋㅋㅋ 🤢🤮  https://t.c...   \n",
       "38  1082866433644650496  그냐앙. 아아~ 후... 우리동네는 세월이 지나도 이렇게 변하질 않냐? 집값도 안 ...   \n",
       "39  1082866300517380097  [트윗만평]집을가진이들은 집값이 내려간다고 울며 어렵다하며, 집을가지지못한이들은 집...   \n",
       "40  1082864182205140992  을지로밀고 뭐 거기에다가 새공장이나 새공업단지 지어서 원래 일하시던분들 옮기라고 하...   \n",
       "41  1082862237243498496  박원순 집값 잡기 올인…“공공임대주택 40만호 공급”  https://t.co/GT...   \n",
       "42  1082860975865266176  #참고 공시가격은 실제 집값이 변동하는 상황을 반영하여 결정된 것으로 지역별로 개별...   \n",
       "43  1082859754815287296  한국감정원 관계자 \"수도권 주택공급 계획, 9·13 대책 등 정부 규제, 금리 인상...   \n",
       "44  1082856881738137601  [부동산] 올해 부산 집값 떨어질듯  #부산부동산 #주택 #전월세 #집값하락 #부동...   \n",
       "45  1082852997221081088   집값, 얼마나 떨어져야 거래절벽 탈출할까?  https://t.co/UixRJtat81   \n",
       "46  1082844711679778816  사실 부자동네에 예전부터 오래산 노인들 중에 살고 있는 집값은 그동안 올라서 서류상...   \n",
       "47  1082837130357878785    @webber_27_A @Siegeslauf 집값 떨어집니다 (10년째 똑같은 이야기   \n",
       "48  1082830108182884352  @coreazang @kjy24k 집값 올라도 세금이나 기타 유지비가 감당이 되지 ...   \n",
       "\n",
       "    label  predicted  \n",
       "0       0          0  \n",
       "1       0          0  \n",
       "2       0          1  \n",
       "3       0          0  \n",
       "4       0          1  \n",
       "5       0          0  \n",
       "6       0          1  \n",
       "7       0          1  \n",
       "8       0          1  \n",
       "9       0          1  \n",
       "10      0          1  \n",
       "11      0          0  \n",
       "12      0          0  \n",
       "13      3          1  \n",
       "14      0          0  \n",
       "15      0          0  \n",
       "16      0          1  \n",
       "17      2          0  \n",
       "18      0          0  \n",
       "19      0          1  \n",
       "20      0          1  \n",
       "21      0          1  \n",
       "22     11          0  \n",
       "23      2          1  \n",
       "24      0          1  \n",
       "25      0          0  \n",
       "26      0          0  \n",
       "27      0          1  \n",
       "28      1          0  \n",
       "29      0          0  \n",
       "30      0          1  \n",
       "31      0          1  \n",
       "32      0          1  \n",
       "33      0          1  \n",
       "34      0          1  \n",
       "35      0          1  \n",
       "36      0          1  \n",
       "37      0          1  \n",
       "38      0          0  \n",
       "39      0          1  \n",
       "40      0          0  \n",
       "41      0          1  \n",
       "42     68          0  \n",
       "43      0          1  \n",
       "44      0          1  \n",
       "45      0          1  \n",
       "46      0          1  \n",
       "47      0          1  \n",
       "48      0          1  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test['predicted']= lab\n",
    "dataset_test.head(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "427e414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 40\n"
     ]
    }
   ],
   "source": [
    "pos= 0\n",
    "neg=0\n",
    "\n",
    "for item in dataset_test['predicted']:\n",
    "    if item==1:\n",
    "        pos+=1\n",
    "    else:\n",
    "        neg+=1\n",
    "        \n",
    "        \n",
    "print(pos, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f5856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
